{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1479D_7bnXfmwIl1S2uDTM1K7uVm86yV9",
      "authorship_tag": "ABX9TyPCIgfFBcuf3lA7hc/tbs6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harveyrutland/pdf_scanner/blob/main/paper_scanner_ML_algorithmns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob_YgkZF8lt9",
        "outputId": "ab874066-8fce-49cf-acf6-9a9701483ddc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer\n",
            "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pdfminer\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140096 sha256=f8a18a13fbd5a2a5d17ccbc24a513f3a51b2cb9340275d0d6c5cf7fa7d3f360d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/28/7d/f390b82bb0307deb63ff27a1474fd308ec68ee028cb9ab6283\n",
            "Successfully built pdfminer\n",
            "Installing collected packages: pycryptodome, pdfminer\n",
            "Successfully installed pdfminer-20191125 pycryptodome-3.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from io import StringIO\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.converter import PDFPageAggregator\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pdf_to_text(pdf_file):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file and returns it as a list of strings (one string per page).\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    with open(pdf_file, 'rb') as fh:\n",
        "        # Create a PDF resource manager object that stores shared resources\n",
        "        rsrcmgr = PDFResourceManager()\n",
        "        # Create a layout analyzer object\n",
        "        laparams = LAParams()\n",
        "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
        "        # Create a PDF interpreter object\n",
        "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "        # Extract text from each page and append it to the text list\n",
        "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
        "            interpreter.process_page(page)\n",
        "            layout = device.get_result()\n",
        "            for lt_obj in layout:\n",
        "                if hasattr(lt_obj, \"get_text\"):\n",
        "                    text.append(lt_obj.get_text())\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "# Assume that the location of your PDF files is stored in the variable pdf_dir\n",
        "pdf_dir = \"/content/drive/MyDrive/PhD/Survey_Paper/\"\n",
        "\n",
        "# Use the os.listdir() function to get a list of all files in the directory\n",
        "pdf_files = os.listdir(pdf_dir)\n",
        "\n",
        "# Iterate over the list of files\n",
        "for pdf_file_name in pdf_files:\n",
        "    # Check if the file is a PDF\n",
        "    if pdf_file_name.endswith(\".pdf\"):\n",
        "        # Print the name of the file\n",
        "        # print(pdf_file)\n",
        "\n",
        "        pdf_file = pdf_dir + str(pdf_file_name)\n",
        "        papers = pdf_to_text(pdf_file)\n",
        "\n",
        "\n",
        "        models = {\n",
        "            \"Linear Regression\": [\"Linear Regression\", \"LR\",\"Simple Linear Regression\",\"Multiple Linear Regression\"],\n",
        "            \"Logistic Regression\": [\"Logistic Regression\", \"LogReg\",\"Binary Logistic Regression\",\"Multinomial Logistic Regression\",\"Ordinal Logistic Regression\"],\n",
        "            \"Decision Trees\": [\"Decision Trees\", \"DT\",\"CART\",\"ID3\",\"C4.5\",\"CHAID\",\"Random Forest\"],\n",
        "            \"Random Forest\": [\"Random Forest\", \"RF\",\"RandomForest\",\"Random Forest Classifier\",\"Random Forest Regressor\"],\n",
        "            \"Gradient Boosting\": [\"GB\",\"GBM\",\"LightGBM\",\"CatBoost\"],\n",
        "            \"Support Vector Machine (SVM)\": [\"SVM\", \"Support Vector Machine\",\"Linear SVM\",\"Non-Linear SVM\"],\n",
        "            \"k-Nearest Neighbors (k-NN)\": [\"k-NN\", \"k-Nearest Neighbors\",\"KNN\"],\n",
        "            \"Neural Networks\": [\"NN\", \"Neural Network\", \"MLP\", \"Perception\",\"CNN\",\"RNN\",\"DNN\",\"Autoencoder\",\"Deep Belief Networks\", \"deep learning\"],\n",
        "            \"Naive Bayes\": [\"Naive Bayes\", \"NB\",\"Gaussian Naive Bayes\",\"Multinomial Naive Bayes\",\"Bernoulli Naive Bayes\"],\n",
        "            \"k-Means Clustering\": [\"k-Means\", \"KMeans\"],\n",
        "            \"Principal Component Analysis (PCA)\": [\"PCA\"],\n",
        "            \"Singular Value Decomposition (SVD)\": [\"SVD\"],\n",
        "            \"Latent Dirichlet Allocation (LDA)\": [\"LDA\"],\n",
        "            \"t-Distributed Stochastic Neighbor Embedding (t-SNE)\": [\"t-SNE\",\"tSNE\"],\n",
        "            \"Generative Adversarial Networks (GAN)\": [\"GAN\",\"Generative Adversarial Networks\"],\n",
        "            \"Autoencoder\": [\"Autoencoder\",\"AE\",\"Autoencoders\"],\n",
        "            \"Q-Learning, Reinforcement Learning\": [\"Q-Learning\",\"Reinforcement Learning\",\"RL\"],\n",
        "            \"Bagging, Boosting, AdaBoost\": [\"Bagging\",\"Boosting\",\"AdaBoost\"],\n",
        "            \"Markov Chain Monte Carlo (MCMC)\": [\"MCMC\",\"Markov Chain Monte Carlo\"],\n",
        "            \"Hidden Markov Models\": [\"HMM\",\"Hidden Markov Models\"],\n",
        "            \"Conditional Random Fields\": [\"CRF\",\"Conditional Random Fields\"],\n",
        "            \"Boltzmann Machines\": [\"BM\",\"Boltzmann Machines\"],\n",
        "            \"Random Projection\": [\"Random Projection\",\"RP\"],\n",
        "            \"Gaussian Mixture Model\": [\"GMM\",\"Gaussian Mixture Model\"],\n",
        "            \"Variational Autoencoder\": [\"VAE\",\"Variational Autoencoder\"],\n",
        "            \"Extreme Gradient Boosting\": [\"XGBoost\",\"LightGBM\",\"CatBoost\"],\n",
        "            \"BERT, GPT, transformer-based models\": [\"BERT\",\"GPT\",\"transformer-based models\"]\n",
        "            }\n",
        "          \n",
        "\n",
        "\n",
        "        combined = []\n",
        "\n",
        "        # Iterate over the papers\n",
        "        paper_models = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for paper in papers:\n",
        "            \n",
        "\n",
        "            # Iterate over the models dictionary\n",
        "            for model_type, model_synonyms in models.items():\n",
        "                # Iterate over the synonyms of the model\n",
        "                for model_synonym in model_synonyms:\n",
        "                    # Check if the synonym is in the paper text\n",
        "                    if re.search(r\"\\b\"+model_synonym+r\"\\b\", paper):\n",
        "                      paper_models.append(model_type)\n",
        "            \n",
        "\n",
        "\n",
        "        paper_models = list( dict.fromkeys(paper_models))\n",
        "        print(pdf_file_name, paper_models)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocW47NNwso_2",
        "outputId": "5e966e5c-41db-42b7-bd6c-1c4accdc470b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paper1.pdf ['Extreme Gradient Boosting', 'Decision Trees', 'Random Forest', 'Gradient Boosting', 'Support Vector Machine (SVM)', 'Neural Networks', 'Bagging, Boosting, AdaBoost']\n"
          ]
        }
      ]
    }
  ]
}